{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install fairseq\n",
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.2.0+cu121.html\n",
        "!pip install torch_geometric==2.0.4\n",
        "!pip install thop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGrvPoUNlv4k",
        "outputId": "ed27f3b5-9b5f-4e26-91a7-8b7ba1bbe23b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fairseq\n",
            "  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq) (1.16.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq) (3.0.10)\n",
            "Collecting hydra-core<1.1,>=1.0.7 (from fairseq)\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.1 (from fairseq)\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq) (2024.5.15)\n",
            "Collecting sacrebleu>=1.4.12 (from fairseq)\n",
            "  Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.3.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fairseq) (4.66.4)\n",
            "Collecting bitarray (from fairseq)\n",
            "  Downloading bitarray-2.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.3/288.3 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fairseq) (1.25.2)\n",
            "Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq)\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq) (4.12.2)\n",
            "Collecting portalocker (from sacrebleu>=1.4.12->fairseq)\n",
            "  Downloading portalocker-2.10.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.9.0)\n",
            "Collecting colorama (from sacrebleu>=1.4.12->fairseq)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (4.9.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.15.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->fairseq)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->fairseq)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->fairseq)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->fairseq)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->fairseq)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->fairseq)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->fairseq)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->fairseq)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->fairseq)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->fairseq)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->fairseq)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->fairseq)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->fairseq) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->fairseq) (1.3.0)\n",
            "Building wheels for collected packages: fairseq, antlr4-python3-runtime\n",
            "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=11289142 sha256=27e885dfb89c0e53b2946aee6f93a357ab3d547a8ea2d6a5c47ccb60e4bfa065\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/35/55/9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141211 sha256=13894bef9d76a0e1b859a00b5ab03250aa4c25b24119710ceea2c7e71d57e371\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
            "Successfully built fairseq antlr4-python3-runtime\n",
            "Installing collected packages: bitarray, antlr4-python3-runtime, portalocker, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, colorama, sacrebleu, nvidia-cusparse-cu12, nvidia-cudnn-cu12, hydra-core, nvidia-cusolver-cu12, fairseq\n",
            "Successfully installed antlr4-python3-runtime-4.8 bitarray-2.9.2 colorama-0.4.6 fairseq-0.12.2 hydra-core-1.0.7 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 omegaconf-2.0.6 portalocker-2.10.0 sacrebleu-2.4.2\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.2.0+cu121.html\n",
            "Collecting pyg_lib\n",
            "  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu121/pyg_lib-0.4.0%2Bpt22cu121-cp310-cp310-linux_x86_64.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu121/torch_scatter-2.1.2%2Bpt22cu121-cp310-cp310-linux_x86_64.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu121/torch_sparse-0.6.18%2Bpt22cu121-cp310-cp310-linux_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu121/torch_cluster-1.6.3%2Bpt22cu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_spline_conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu121/torch_spline_conv-1.2.2%2Bpt22cu121-cp310-cp310-linux_x86_64.whl (943 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m943.4/943.4 kB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.25.2)\n",
            "Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\n",
            "Successfully installed pyg_lib-0.4.0+pt22cu121 torch_cluster-1.6.3+pt22cu121 torch_scatter-2.1.2+pt22cu121 torch_sparse-0.6.18+pt22cu121 torch_spline_conv-1.2.2+pt22cu121\n",
            "Collecting torch_geometric==2.0.4\n",
            "  Downloading torch_geometric-2.0.4.tar.gz (407 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.5/407.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.0.4) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.0.4) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.0.4) (1.11.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.0.4) (2.0.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.0.4) (3.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.0.4) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.0.4) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.0.4) (1.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric==2.0.4) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->torch_geometric==2.0.4) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->torch_geometric==2.0.4) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->torch_geometric==2.0.4) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.0.4) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.0.4) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.0.4) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.0.4) (2024.6.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric==2.0.4) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric==2.0.4) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->torch_geometric==2.0.4) (1.16.0)\n",
            "Building wheels for collected packages: torch_geometric\n",
            "  Building wheel for torch_geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.0.4-py3-none-any.whl size=616579 sha256=376e54ffc33a179534348293c92b20e3aa381f6b37ce5942f0b75a4129c3b427\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/0f/9d/84a397fb5e2761b2219529d8f8cc5a29252f08deda19ce51f3\n",
            "Successfully built torch_geometric\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.0.4\n",
            "Collecting thop\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from thop) (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.15.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->thop) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->thop) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->thop) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->thop) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->thop) (1.3.0)\n",
            "Installing collected packages: thop\n",
            "Successfully installed thop-0.1.1.post2209072238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "A_IvxcsBOhGn",
        "outputId": "50db3e95-4899-42a2-cd6d-323190da4a3d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.3.0+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -r /content/drive/MyDrive/KLTN/requirements.txt"
      ],
      "metadata": {
        "id": "pifSyKfoPQd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/KLTN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvAoXmUIPXlW",
        "outputId": "1514919a-fa1f-4471-fb83-a4bcc70a3b0a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HILL-master  HILL-master.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/KLTN/HILL-master\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fugr1dYR9H7",
        "outputId": "093b9617-458d-4922-cce8-f3b615f93eb3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/KLTN/HILL-master\n",
            "arg_parser.py  config  eval.py\tmain.ipynb  __pycache__  test.py   utils.py\n",
            "ckpt\t       data    LICENSE\tmodel\t    README.md\t train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ./data/wos\n",
        "!python preprocess_wos.py"
      ],
      "metadata": {
        "id": "GnBIpta1TkK8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "971ea937-b997-4a3d-b269-49a7344b57f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/KLTN/HILL-master/data/wos\n",
            "{'5-48': ['Senior Health'], '0-7': ['Parallel computing'], '5-18': ['Emergency Contraception'], '1-0': ['Electricity'], '5-27': ['Hypothyroidism'], '2-7': ['Depression'], '1-4': ['Digital control'], '5-11': ['Birth Control'], '5-31': ['Low Testosterone'], '2-8': ['Borderline personality disorder'], '1-7': ['Microcontroller'], '1-15': ['Operational amplifier'], '0-12': ['Symbolic computation'], '0-13': ['Algorithm design'], '1-5': ['System identification'], '4-7': ['Green Building'], '2-16': ['False memories'], '2-15': ['Gender roles'], '5-23': ['Heart Disease'], '5-37': ['Myelofibrosis'], '0-1': ['Machine learning'], '0-9': ['Software engineering'], '5-40': ['Osteoporosis'], '5-1': ['Allergies'], '5-8': ['Autism'], '5-34': ['Menopause'], '0-11': ['Structured Storage'], '4-10': ['Smart Material'], '4-4': ['Water Pollution'], '6-0': ['Molecular biology'], '5-24': ['Hepatitis C'], '0-14': ['Computer programming'], '2-3': ['Nonverbal communication'], '0-2': ['network security'], '2-1': ['Social cognition'], '5-2': [\"Alzheimer's Disease\"], '5-42': ['Parenting'], '3-4': ['Fluid mechanics'], '0-4': ['Operating systems'], '3-7': ['Materials Engineering'], '2-13': ['Prenatal development'], '0-10': ['Distributed computing'], '6-6': ['Polymerase chain reaction'], '0-0': ['Computer vision'], '6-1': ['Cell biology'], '1-10': ['Electric motor', 'Single-phase electric power', 'Satellite radio'], '1-12': ['Signal-flow graph'], '2-5': ['Leadership'], '3-3': ['Machine design'], '5-38': ['Cancer'], '0-8': ['Relational databases'], '5-3': ['Ankylosing Spondylitis'], '3-1': ['Hydraulics'], '3-2': ['Manufacturing engineering'], '0-15': ['Data structures'], '6-4': ['Genetics'], '0-16': ['Bioinformatics'], '2-0': ['Prejudice'], '2-14': ['Child abuse'], '2-2': ['Person perception'], '5-4': ['Anxiety'], '5-13': [\"Crohn's Disease\"], '6-7': ['Northern blotting'], '6-2': ['Human Metabolism'], '5-28': ['Idiopathic Pulmonary Fibrosis'], '0-3': ['Cryptography'], '4-3': ['Rainwater Harvesting'], '2-6': ['Eating disorders'], '4-0': ['Ambient Intelligence'], '5-15': ['Diabetes'], '2-11': ['Antisocial personality disorder'], '1-9': ['Analog signal processing', 'Electrical generator'], '6-3': ['Immunology'], '4-9': ['Construction Management'], '2-12': ['Media violence'], '5-33': ['Medicare'], '5-50': ['Sports Injuries'], '5-29': ['Irritable Bowel Syndrome'], '3-5': ['Internal combustion engine'], '5-14': ['Dementia'], '5-16': ['Weight Loss'], '5-22': ['Healthy Sleep'], '5-21': ['Headache'], '4-5': ['Suspension Bridge'], '5-5': ['Asthma'], '5-0': ['Addiction'], '4-8': ['Solar Energy'], '5-19': ['Mental Health'], '3-6': ['Thermodynamics'], '6-8': ['Southern blotting'], '3-0': ['computer-aided design'], '5-39': ['Osteoarthritis'], '4-6': ['Stealth Technology'], '6-5': ['Enzymology'], '5-41': ['Overactive Bladder'], '0-5': ['Computer graphics'], '1-14': ['PID controller'], '1-6': ['Electrical network'], '5-47': ['Rheumatoid Arthritis'], '5-52': ['Stress Management'], '5-26': ['HIV/AIDS'], '5-32': ['Lymphoma'], '5-6': ['Atopic Dermatitis'], '5-44': ['Polycythemia Vera'], '5-43': [\"Parkinson's Disease\"], '2-4': ['Prosocial behavior'], '2-10': ['Schizophrenia'], '0-6': ['Image processing'], '5-7': ['Atrial Fibrillation', 'Depression'], '5-9': ['Skin Care'], '2-18': ['Problem-solving'], '2-17': ['Attention'], '4-2': ['Remote Sensing'], '3-8': ['Strength of materials'], '5-45': ['Psoriasis'], '1-2': ['Electrical circuits'], '5-49': ['Smoking Cessation'], '5-36': ['Multiple Sclerosis'], '1-11': ['Control engineering'], '1-13': ['State space representation'], '4-1': ['Geotextile'], '5-17': ['Digestive Health'], '2-9': ['Seasonal affective disorder'], '5-12': [\"Children's Health\"], '5-20': ['Fungal Infection'], '5-10': ['Bipolar Disorder'], '5-35': ['Migraine'], '1-1': ['Lorentz force law']}\n",
            "1-10 ['Electric motor', 'Single-phase electric power', 'Satellite radio']\n",
            "1-9 ['Analog signal processing', 'Electrical generator']\n",
            "5-7 ['Atrial Fibrillation', 'Depression']\n",
            "4\n",
            "128\n",
            "640 160 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python data_wos.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYHm2YLiL9Ip",
        "outputId": "7efa5c55-aaa0-44e0-90e6-e7706a593b63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rtokenizer_config.json:   0% 0.00/48.0 [00:00<?, ?B/s]\rtokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 401kB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "config.json: 100% 570/570 [00:00<00:00, 3.71MB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 3.64MB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 3.96MB/s]\n",
            "2024-06-04 10:06:58.903330: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-06-04 10:06:58.903391: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-06-04 10:06:58.909737: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-06-04 10:06:58.917966: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-06-04 10:07:00.004885: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-06-04 10:07:02 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/ductri/reuters_loader.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ssi7eb_R_J2u",
        "outputId": "92d8ad0c-2385-4258-9543-fc8fc5841cf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'reuters_loader'...\n",
            "remote: Enumerating objects: 53, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 53 (delta 1), reused 0 (delta 0), pack-reused 47\u001b[K\n",
            "Receiving objects: 100% (53/53), 10.98 KiB | 1.22 MiB/s, done.\n",
            "Resolving deltas: 100% (21/21), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/reuters_loader/main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rlkti7l_XEp",
        "outputId": "728a5d9c-4336-4b89-84e9-551eb3a37f6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: main.py [-h] root_dir\n",
            "main.py: error: the following arguments are required: root_dir\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/KLTN/HILL-master\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YY9pmDz5mha6",
        "outputId": "69f1404a-5ff6-40bc-8526-b2ac63d77f7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/KLTN/HILL-master\n",
            "arg_parser.py  data\tLICENSE     model\t README.md  train.py\n",
            "config\t       eval.py\tmain.ipynb  __pycache__  test.py    utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "BD4ZrBfboXJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !python train.py -d wos -mn gclr -s 0 -b 24 -lr 1e-3 -k 3 -l 1e-3 -hd 768 -tp sum --cfg_dir config"
      ],
      "metadata": {
        "id": "1hLMzONNmiFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py -d wos -mn hill -s 0 -b 24 -lr 1e-3 -k 3 -l 1e-3 -hd 768 -tp sum --cfg_dir config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fi6vjJqoDWn7",
        "outputId": "71c1e1d3-8006-40a1-f173-bab487ddfcfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-06-04 10:11:29.555611: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-06-04 10:11:29.555660: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-06-04 10:11:29.557059: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-06-04 10:11:29.564798: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-06-04 10:11:30.600237: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-06-04 10:11:32 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "Namespace(dataset='wos', model_name='hill', name='', seed=0, batch_size=24, learning_rate=0.001, l2_rate=0.01, lamda=0.001, freeze=False, wandb=False, tree_depth=3, hidden_dim=768, hidden_dropout=0.5, tree_pooling_type='sum', hrl_output='bert', graph_conv='GIN', graph_pooling_type='sum', conv_layers=3, graph_output='graph', residual=False, graph=True, contrast_loss=True, cls_loss=True, multi_label=True, data_dir='data', ckpt_dir='ckpt', cfg_dir='config', begin_time='0604_1011')\n",
            "2024-06-04 10:11:34 | INFO | fairseq.data.data_utils | loaded 1,000 examples from: data/wos/tok\n",
            "2024-06-04 10:11:34 | INFO | fairseq.data.data_utils | loaded 1,000 examples from: data/wos/Y\n",
            "Some weights of StructureContrast were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'node_mask', 'structure_encoder.convs.0.nn.0.bias', 'structure_encoder.convs.0.nn.0.weight', 'structure_encoder.convs.0.nn.1.bias', 'structure_encoder.convs.0.nn.1.num_batches_tracked', 'structure_encoder.convs.0.nn.1.running_mean', 'structure_encoder.convs.0.nn.1.running_var', 'structure_encoder.convs.0.nn.1.weight', 'structure_encoder.convs.0.nn.3.bias', 'structure_encoder.convs.0.nn.3.weight', 'structure_encoder.convs.0.nn.4.bias', 'structure_encoder.convs.0.nn.4.num_batches_tracked', 'structure_encoder.convs.0.nn.4.running_mean', 'structure_encoder.convs.0.nn.4.running_var', 'structure_encoder.convs.0.nn.4.weight', 'structure_encoder.convs.1.nn.0.bias', 'structure_encoder.convs.1.nn.0.weight', 'structure_encoder.convs.1.nn.1.bias', 'structure_encoder.convs.1.nn.1.num_batches_tracked', 'structure_encoder.convs.1.nn.1.running_mean', 'structure_encoder.convs.1.nn.1.running_var', 'structure_encoder.convs.1.nn.1.weight', 'structure_encoder.convs.1.nn.3.bias', 'structure_encoder.convs.1.nn.3.weight', 'structure_encoder.convs.1.nn.4.bias', 'structure_encoder.convs.1.nn.4.num_batches_tracked', 'structure_encoder.convs.1.nn.4.running_mean', 'structure_encoder.convs.1.nn.4.running_var', 'structure_encoder.convs.1.nn.4.weight', 'structure_encoder.convs.2.nn.0.bias', 'structure_encoder.convs.2.nn.0.weight', 'structure_encoder.convs.2.nn.2.bias', 'structure_encoder.convs.2.nn.2.weight', 'structure_encoder.dim_align.1.bias', 'structure_encoder.dim_align.1.weight', 'text_proj.0.bias', 'text_proj.0.weight', 'text_proj.2.bias', 'text_proj.2.weight', 'trans_dup.0.bias', 'trans_dup.0.weight', 'trans_dup.2.bias', 'trans_dup.2.weight', 'trans_proj.0.bias', 'trans_proj.0.weight', 'trans_proj.2.bias', 'trans_proj.2.weight', 'tree_proj.0.bias', 'tree_proj.0.weight', 'tree_proj.2.bias', 'tree_proj.2.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Training model:   0% 0/200 [00:00<?, ?Epoch/s]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:03<01:18,  3.02s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:05<01:02,  2.52s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:07<00:56,  2.35s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:09<00:52,  2.27s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:11<00:49,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:44,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:42,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:39,  2.08s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:36,  2.04s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:21<00:34,  2.03s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:23<00:33,  2.07s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:31,  2.11s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:29,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:30<00:28,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:32<00:26,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:34<00:23,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:21,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:38<00:18,  2.06s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:41<00:16,  2.11s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:42<00:14,  2.02s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:44<00:12,  2.01s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:47<00:10,  2.08s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:49<00:08,  2.12s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:51<00:06,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:53<00:04,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:55<00:02,  2.18s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:57<00:00,  1.99s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.45batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.61batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.57batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.51batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.49batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.47batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.56batch/s]\n",
            "epoch: 0\t loss: 4.708659\t micro_f1: 0.1437\t macro_f1: 0.0047\n",
            "Training model:   0% 1/200 [01:20<4:27:14, 80.58s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:59,  2.28s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:56,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:54,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:09<00:51,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:11<00:49,  2.27s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:47,  2.27s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:45,  2.30s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:18<00:43,  2.30s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:20<00:41,  2.31s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:22<00:39,  2.30s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:25<00:37,  2.32s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:27<00:34,  2.31s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:29<00:32,  2.30s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:31<00:27,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:33<00:26,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:36<00:24,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:20,  2.09s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:39<00:18,  2.06s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:42<00:16,  2.12s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:44<00:15,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:46<00:13,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:48<00:10,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:51<00:08,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:53<00:06,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:55<00:04,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:57<00:02,  2.24s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:59<00:00,  2.03s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.43batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.57batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.54batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:02,  1.49batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.47batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.45batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.55batch/s]\n",
            "epoch: 1\t loss: 1.533758\t micro_f1: 0.1221\t macro_f1: 0.0045\n",
            "Training model:   1% 2/200 [02:24<3:53:54, 70.88s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:58,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:54,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:53,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:49,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:10<00:47,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:46,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:44,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:39,  2.10s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:38,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:21<00:36,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:23<00:35,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:33,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:31,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:30<00:28,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:32<00:26,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:34<00:22,  2.05s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:36<00:21,  2.11s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:39<00:19,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:40<00:16,  2.08s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:42<00:14,  2.03s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:45<00:12,  2.09s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:47<00:10,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:49<00:08,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:51<00:06,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:54<00:04,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:56<00:02,  2.16s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:57<00:00,  1.97s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.45batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.61batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.57batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.52batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.49batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:03<00:00,  1.48batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.57batch/s]\n",
            "epoch: 2\t loss: 1.449105\t micro_f1: 0.2143\t macro_f1: 0.0125\n",
            "Training model:   2% 3/200 [03:40<4:00:25, 73.23s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:59,  2.28s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:56,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:52,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:47,  2.08s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:10<00:47,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:12<00:45,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:43,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:41,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:39,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:21<00:37,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:24<00:36,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:34,  2.27s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:30,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:30<00:28,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:33<00:26,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:35<00:24,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:22,  2.27s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:39<00:20,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:41<00:17,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:44<00:15,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:46<00:13,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:48<00:11,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:50<00:08,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:52<00:06,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:54<00:04,  2.04s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:56<00:02,  2.12s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:58<00:00,  1.94s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.45batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.61batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.57batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.52batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.48batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.46batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.56batch/s]\n",
            "epoch: 3\t loss: 1.374053\t micro_f1: 0.2842\t macro_f1: 0.0181\n",
            "Training model:   2% 4/200 [05:06<4:15:21, 78.17s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:58,  2.27s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:54,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:53,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:51,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:11<00:49,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:47,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:43,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:42,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:20<00:40,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:22<00:38,  2.28s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:24<00:36,  2.29s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:27<00:34,  2.29s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:29<00:32,  2.30s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:31<00:29,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:33<00:27,  2.28s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:36<00:25,  2.29s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:38<00:22,  2.30s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:40<00:20,  2.29s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:43<00:18,  2.29s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:45<00:16,  2.29s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:47<00:13,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:49<00:11,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:51<00:08,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:53<00:06,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:56<00:04,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:58<00:02,  2.21s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:59<00:00,  1.94s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.42batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.57batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.54batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:02,  1.48batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.46batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.44batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.54batch/s]\n",
            "epoch: 4\t loss: 1.299947\t micro_f1: 0.3587\t macro_f1: 0.0221\n",
            "Training model:   2% 5/200 [06:22<4:11:35, 77.42s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:59,  2.28s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:53,  2.13s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:51,  2.13s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:49,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:10<00:48,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:46,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:44,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:42,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:39,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:22<00:37,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:24<00:35,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:33,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:31,  2.27s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:31<00:29,  2.28s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:33<00:26,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:35<00:24,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:22,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:39<00:19,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:42<00:17,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:44<00:14,  2.12s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:46<00:13,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:48<00:11,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:50<00:08,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:52<00:06,  2.07s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:54<00:04,  2.13s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:57<00:02,  2.17s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:58<00:00,  1.91s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.41batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.56batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.55batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:02,  1.50batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.47batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.45batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.54batch/s]\n",
            "epoch: 5\t loss: 1.226317\t micro_f1: 0.3866\t macro_f1: 0.0255\n",
            "Training model:   3% 6/200 [07:36<4:06:43, 76.31s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<01:00,  2.31s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:56,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:53,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:51,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:11<00:49,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:47,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:45,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:18<00:42,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:38,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:22<00:37,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:24<00:35,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:33,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:29<00:31,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:31<00:29,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:33<00:27,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:35<00:24,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:38<00:22,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:40<00:20,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:42<00:17,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:44<00:15,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:46<00:13,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:49<00:11,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:51<00:08,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:53<00:06,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:55<00:04,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:57<00:02,  2.14s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:58<00:00,  1.89s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.44batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.60batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.56batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.51batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.48batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.46batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.56batch/s]\n",
            "epoch: 6\t loss: 1.150929\t micro_f1: 0.4130\t macro_f1: 0.0295\n",
            "Training model:   4% 7/200 [08:54<4:06:50, 76.74s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:59,  2.30s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:52,  2.10s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:52,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:50,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:10<00:47,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:46,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:44,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:41,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:38,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:21<00:37,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:24<00:35,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:33,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:31,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:31<00:29,  2.27s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:33<00:27,  2.28s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:35<00:25,  2.28s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:22,  2.29s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:40<00:20,  2.29s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:42<00:18,  2.28s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:44<00:15,  2.28s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:46<00:13,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:49<00:11,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:51<00:09,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:53<00:06,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:55<00:04,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:57<00:02,  2.13s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:59<00:00,  1.95s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.45batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.62batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.58batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.52batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.49batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:03<00:00,  1.48batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.57batch/s]\n",
            "epoch: 7\t loss: 1.086123\t micro_f1: 0.4184\t macro_f1: 0.0326\n",
            "Training model:   4% 8/200 [10:11<4:05:35, 76.75s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:58,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:53,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:52,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:47,  2.08s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:10<00:47,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:12<00:44,  2.13s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:43,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:41,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:40,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:21<00:38,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:24<00:36,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:33,  2.27s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:31,  2.27s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:31<00:29,  2.28s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:32<00:25,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:35<00:23,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:22,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:39<00:18,  2.11s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:41<00:17,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:43<00:14,  2.02s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:45<00:12,  2.03s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:47<00:10,  2.10s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:49<00:08,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:52<00:06,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:54<00:04,  2.12s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:56<00:02,  2.16s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:57<00:00,  1.98s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.45batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.60batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.57batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.50batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.47batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.45batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.55batch/s]\n",
            "epoch: 8\t loss: 1.007840\t micro_f1: 0.4247\t macro_f1: 0.0312\n",
            "Training model:   4% 9/200 [11:25<4:01:45, 75.95s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:01<00:51,  2.00s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:53,  2.13s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:52,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:49,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:10<00:48,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:46,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:14<00:41,  2.09s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:16<00:39,  2.08s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:37,  2.10s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:21<00:36,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:23<00:35,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:25<00:33,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:31,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:30<00:29,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:32<00:27,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:35<00:24,  2.27s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:21,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:39<00:19,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:41<00:17,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:43<00:15,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:46<00:13,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:48<00:11,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:50<00:09,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:52<00:06,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:55<00:04,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:57<00:02,  2.25s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:58<00:00,  2.04s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.42batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.58batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.53batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:02,  1.48batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.46batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.45batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.54batch/s]\n",
            "epoch: 9\t loss: 0.948041\t micro_f1: 0.4639\t macro_f1: 0.0364\n",
            "Training model:   5% 10/200 [12:39<3:59:12, 75.54s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:59,  2.30s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:03<00:48,  1.93s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:49,  2.06s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:49,  2.13s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:10<00:47,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:12<00:46,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:43,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:41,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:40,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:21<00:38,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:24<00:35,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:33,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:31,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:30<00:28,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:32<00:26,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:35<00:24,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:21,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:39<00:19,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:41<00:17,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:43<00:15,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:46<00:13,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:48<00:11,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:50<00:08,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:52<00:06,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:55<00:04,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:57<00:02,  2.15s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:58<00:00,  1.87s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.42batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.56batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.53batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:02,  1.49batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.47batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.46batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.55batch/s]\n",
            "epoch: 10\t loss: 0.881441\t micro_f1: 0.4414\t macro_f1: 0.0367\n",
            "Training model:   6% 11/200 [14:02<4:05:12, 77.84s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:59,  2.28s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:52,  2.11s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:51,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:50,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:10<00:48,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:12<00:44,  2.13s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:43,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:42,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:39,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:21<00:37,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:24<00:35,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:33,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:31,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:31<00:29,  2.28s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:33<00:27,  2.29s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:35<00:25,  2.30s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:23,  2.30s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:40<00:20,  2.31s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:42<00:18,  2.30s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:44<00:15,  2.27s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:46<00:13,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:49<00:11,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:51<00:09,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:53<00:06,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:56<00:04,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:58<00:02,  2.26s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:59<00:00,  2.05s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.42batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.56batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.55batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.51batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.48batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.46batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.55batch/s]\n",
            "epoch: 11\t loss: 0.822150\t micro_f1: 0.4547\t macro_f1: 0.0446\n",
            "Training model:   6% 12/200 [15:12<3:56:22, 75.44s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:58,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:56,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:53,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:51,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:11<00:48,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:45,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:43,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:41,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:39,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:22<00:37,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:24<00:35,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:33,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:31,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:31<00:28,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:33<00:26,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:35<00:24,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:22,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:40<00:20,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:42<00:18,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:44<00:15,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:46<00:13,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:49<00:11,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:51<00:09,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:53<00:06,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:55<00:04,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:57<00:02,  2.19s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:58<00:00,  1.89s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.42batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.57batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.54batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:02,  1.48batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.45batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.45batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.54batch/s]\n",
            "epoch: 12\t loss: 0.760413\t micro_f1: 0.4619\t macro_f1: 0.0503\n",
            "Training model:   6% 13/200 [16:27<3:53:56, 75.06s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:57,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:52,  2.08s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:51,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:50,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:10<00:47,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:46,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:42,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:41,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:38,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:21<00:37,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:23<00:35,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:25<00:32,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:30,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:30<00:27,  2.12s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:32<00:25,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:34<00:24,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:22,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:39<00:20,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:41<00:17,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:43<00:15,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:45<00:13,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:47<00:11,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:50<00:08,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:52<00:06,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:54<00:04,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:56<00:02,  2.23s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:58<00:00,  2.02s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.42batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.57batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.55batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.50batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.48batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.47batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.55batch/s]\n",
            "epoch: 13\t loss: 0.692280\t micro_f1: 0.4579\t macro_f1: 0.0575\n",
            "Training model:   7% 14/200 [17:35<3:46:51, 73.18s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<01:00,  2.32s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:56,  2.28s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:54,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:09<00:51,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:11<00:49,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:47,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:45,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:18<00:42,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:20<00:40,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:22<00:37,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:24<00:35,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:33,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:30,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:31<00:27,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:33<00:26,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:35<00:24,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:20,  2.07s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:39<00:18,  2.08s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:41<00:16,  2.04s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:43<00:14,  2.10s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:45<00:12,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:48<00:10,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:50<00:08,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:52<00:06,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:54<00:04,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:56<00:02,  2.20s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:58<00:00,  1.95s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.45batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.59batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.56batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:02,  1.49batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.46batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.45batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.54batch/s]\n",
            "epoch: 14\t loss: 0.634712\t micro_f1: 0.4819\t macro_f1: 0.0613\n",
            "Training model:   8% 15/200 [19:27<4:21:12, 84.72s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:54,  2.09s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:54,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:50,  2.11s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:48,  2.09s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:10<00:45,  2.05s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:12<00:44,  2.13s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:14<00:42,  2.12s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:16<00:40,  2.11s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:38,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:21<00:36,  2.12s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:23<00:32,  2.04s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:25<00:31,  2.10s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:27<00:30,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:29<00:28,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:31<00:25,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:34<00:24,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:36<00:22,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:38<00:20,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:41<00:18,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:43<00:15,  2.27s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:45<00:13,  2.29s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:48<00:11,  2.28s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:49<00:08,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:52<00:06,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:54<00:04,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:56<00:02,  2.22s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:58<00:00,  2.01s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.42batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.59batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.55batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:02,  1.50batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.46batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.44batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.54batch/s]\n",
            "epoch: 15\t loss: 0.575004\t micro_f1: 0.4872\t macro_f1: 0.0781\n",
            "Training model:   8% 16/200 [21:23<4:48:42, 94.14s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:59,  2.30s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:56,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:53,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:09<00:51,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:11<00:48,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:46,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:45,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:43,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:20<00:40,  2.27s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:22<00:38,  2.29s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:24<00:36,  2.31s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:27<00:34,  2.31s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:29<00:32,  2.31s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:31<00:30,  2.31s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:34<00:27,  2.32s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:36<00:25,  2.32s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:38<00:23,  2.32s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:40<00:19,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:42<00:17,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:45<00:15,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:47<00:13,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:49<00:11,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:51<00:08,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:53<00:06,  2.04s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:55<00:04,  2.10s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:57<00:02,  2.14s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:59<00:00,  1.96s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.46batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.62batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.58batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.52batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.49batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:03<00:00,  1.48batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.57batch/s]\n",
            "epoch: 16\t loss: 0.516679\t micro_f1: 0.4805\t macro_f1: 0.0652\n",
            "Training model:   8% 17/200 [22:27<4:19:29, 85.08s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:57,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:55,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:53,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:51,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:11<00:49,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:12<00:42,  2.02s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:41,  2.09s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:40,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:38,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:21<00:35,  2.06s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:23<00:33,  2.07s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:25<00:31,  2.12s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:27<00:30,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:29<00:27,  2.12s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:32<00:25,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:34<00:24,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:36<00:22,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:38<00:19,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:41<00:17,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:43<00:15,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:45<00:13,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:47<00:10,  2.10s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:49<00:08,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:51<00:06,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:54<00:04,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:56<00:02,  2.21s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:57<00:00,  2.01s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.42batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.56batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.54batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:02,  1.49batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.46batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.45batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.54batch/s]\n",
            "epoch: 17\t loss: 0.461936\t micro_f1: 0.4723\t macro_f1: 0.0749\n",
            "Training model:   9% 18/200 [23:29<3:57:32, 78.31s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:58,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:49,  1.98s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:50,  2.10s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:49,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:10<00:48,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:12<00:45,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:43,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:41,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:39,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:21<00:37,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:23<00:34,  2.13s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:25<00:31,  2.08s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:27<00:29,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:30<00:28,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:32<00:26,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:34<00:24,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:36<00:21,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:38<00:19,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:41<00:17,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:43<00:15,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:45<00:13,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:48<00:11,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:50<00:08,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:52<00:06,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:54<00:04,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:57<00:02,  2.25s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:58<00:00,  1.99s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.45batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.61batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.58batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.52batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.49batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:03<00:00,  1.48batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.57batch/s]\n",
            "epoch: 18\t loss: 0.411708\t micro_f1: 0.4990\t macro_f1: 0.0846\n",
            "Training model:  10% 19/200 [24:46<3:54:14, 77.65s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:58,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:55,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:53,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:51,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:10<00:47,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:45,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:43,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:42,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:38,  2.13s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:21<00:36,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:24<00:35,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:33,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:31,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:31<00:29,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:33<00:27,  2.27s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:35<00:25,  2.29s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:22,  2.30s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:40<00:20,  2.30s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:42<00:18,  2.29s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:44<00:16,  2.29s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:47<00:13,  2.29s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:49<00:11,  2.29s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:51<00:08,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:53<00:06,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:55<00:04,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:58<00:02,  2.23s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:59<00:00,  2.02s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.44batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.60batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.57batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.52batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.49batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:03<00:00,  1.47batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.57batch/s]\n",
            "epoch: 19\t loss: 0.370362\t micro_f1: 0.5239\t macro_f1: 0.1048\n",
            "Training model:  10% 20/200 [26:11<3:59:58, 79.99s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:58,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:55,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:53,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:51,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:11<00:49,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:47,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:45,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:41,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:38,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:22<00:36,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:24<00:35,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:32,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:29,  2.13s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:30<00:27,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:32<00:25,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:35<00:24,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:21,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:39<00:19,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:41<00:17,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:44<00:15,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:46<00:13,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:48<00:11,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:50<00:08,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:52<00:06,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:54<00:04,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:57<00:02,  2.24s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:58<00:00,  2.03s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.45batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.61batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.57batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.51batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.49batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.47batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.57batch/s]\n",
            "epoch: 20\t loss: 0.327348\t micro_f1: 0.5259\t macro_f1: 0.1021\n",
            "Training model:  10% 21/200 [27:20<3:48:51, 76.71s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<01:00,  2.31s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:56,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:53,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:51,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:10<00:47,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:45,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:43,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:42,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:39,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:22<00:37,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:24<00:35,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:31,  2.07s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:29,  2.13s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:30<00:27,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:32<00:26,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:34<00:24,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:21,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:38<00:18,  2.02s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:41<00:16,  2.09s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:43<00:15,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:45<00:13,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:47<00:11,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:50<00:08,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:52<00:06,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:54<00:04,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:56<00:02,  2.18s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:58<00:00,  1.99s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.41batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.57batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.55batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:02,  1.50batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.47batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.46batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.55batch/s]\n",
            "epoch: 21\t loss: 0.296671\t micro_f1: 0.5217\t macro_f1: 0.1169\n",
            "Training model:  11% 22/200 [28:48<3:57:34, 80.08s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:58,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:56,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:50,  2.10s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:49,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:10<00:45,  2.05s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:12<00:42,  2.04s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:14<00:42,  2.12s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:41,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:39,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:21<00:36,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:23<00:35,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:33,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:27<00:29,  2.11s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:30<00:28,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:32<00:26,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:34<00:24,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:22,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:39<00:20,  2.27s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:41<00:18,  2.27s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:43<00:14,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:45<00:13,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:48<00:11,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:50<00:08,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:52<00:06,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:54<00:04,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:56<00:02,  2.21s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:58<00:00,  2.01s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.45batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.61batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.57batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.51batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.49batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:03<00:00,  1.47batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.57batch/s]\n",
            "epoch: 22\t loss: 0.265909\t micro_f1: 0.5347\t macro_f1: 0.1150\n",
            "Training model:  12% 23/200 [29:57<3:46:09, 76.66s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:01<00:48,  1.86s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:51,  2.07s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:51,  2.13s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:49,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:10<00:48,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:12<00:45,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:44,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:42,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:40,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:21<00:37,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:24<00:35,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:25<00:31,  2.12s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:30,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:30<00:28,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:32<00:26,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:34<00:24,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:36<00:20,  2.08s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:39<00:19,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:41<00:17,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:43<00:15,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:45<00:13,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:47<00:10,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:50<00:08,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:52<00:06,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:54<00:04,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:56<00:02,  2.18s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:57<00:00,  1.92s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.44batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.59batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.56batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.51batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.48batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.46batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.55batch/s]\n",
            "epoch: 23\t loss: 0.241022\t micro_f1: 0.5248\t macro_f1: 0.1082\n",
            "Training model:  12% 24/200 [30:59<3:32:22, 72.40s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:58,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:56,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:54,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:09<00:51,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:11<00:49,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:47,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:45,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:42,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:20<00:40,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:22<00:38,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:24<00:35,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:33,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:30,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:31<00:28,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:33<00:26,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:35<00:24,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:22,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:40<00:20,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:42<00:17,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:44<00:15,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:46<00:13,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:48<00:10,  2.11s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:50<00:08,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:52<00:06,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:55<00:04,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:57<00:02,  2.21s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:58<00:00,  1.96s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.45batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.62batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.56batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.51batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.47batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.46batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.55batch/s]\n",
            "epoch: 24\t loss: 0.221152\t micro_f1: 0.5187\t macro_f1: 0.1013\n",
            "Training model:  12% 25/200 [32:03<3:23:21, 69.72s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:58,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:56,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:53,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:50,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:10<00:47,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:45,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:43,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:41,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:38,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:21<00:37,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:24<00:35,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:33,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:31,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:30<00:29,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:32<00:26,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:35<00:24,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:22,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:39<00:20,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:41<00:17,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:44<00:15,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:46<00:13,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:48<00:10,  2.11s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:50<00:08,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:52<00:06,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:54<00:04,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:57<00:02,  2.22s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:58<00:00,  2.02s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.45batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.60batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.57batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.51batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.49batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:03<00:00,  1.48batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.57batch/s]\n",
            "epoch: 25\t loss: 0.202222\t micro_f1: 0.5246\t macro_f1: 0.1244\n",
            "Training model:  13% 26/200 [33:13<3:23:08, 70.05s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:58,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:56,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:53,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:51,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:10<00:46,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:44,  2.13s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:43,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:41,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:40,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:22<00:38,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:24<00:36,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:33,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:31,  2.27s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:31<00:28,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:33<00:26,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:35<00:24,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:22,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:40<00:20,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:42<00:17,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:44<00:15,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:46<00:12,  2.10s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:48<00:10,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:50<00:08,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:53<00:06,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:55<00:04,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:57<00:02,  2.15s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:58<00:00,  1.90s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.44batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.60batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.57batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.51batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.49batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.47batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.56batch/s]\n",
            "epoch: 26\t loss: 0.191119\t micro_f1: 0.5347\t macro_f1: 0.1149\n",
            "Training model:  14% 27/200 [34:17<3:16:03, 68.00s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:57,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:49,  1.97s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:50,  2.10s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:49,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:10<00:48,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:46,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:44,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:42,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:40,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:22<00:38,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:24<00:35,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:33,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:31,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:30<00:29,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:33<00:26,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:35<00:24,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:21,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:39<00:19,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:41<00:17,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:44<00:15,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:46<00:13,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:48<00:11,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:50<00:09,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:52<00:06,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:54<00:04,  2.08s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:57<00:02,  2.12s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:58<00:00,  1.86s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.45batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.61batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.57batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.51batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.49batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.46batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.56batch/s]\n",
            "epoch: 27\t loss: 0.179216\t micro_f1: 0.5289\t macro_f1: 0.1212\n",
            "Training model:  14% 28/200 [35:20<3:10:30, 66.46s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:58,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:56,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:53,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:51,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:11<00:49,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:47,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:45,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:18<00:42,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:39,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:22<00:37,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:23<00:32,  2.02s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:31,  2.09s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:29,  2.10s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:30<00:27,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:32<00:26,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:34<00:24,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:22,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:39<00:20,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:41<00:17,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:43<00:15,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:46<00:13,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:48<00:11,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:50<00:08,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:52<00:06,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:55<00:04,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:57<00:02,  2.25s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:58<00:00,  1.97s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.42batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.59batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.55batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.51batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.48batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.47batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.56batch/s]\n",
            "epoch: 28\t loss: 0.163557\t micro_f1: 0.5366\t macro_f1: 0.1270\n",
            "Training model:  14% 29/200 [36:39<3:20:09, 70.23s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:59,  2.30s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:52,  2.08s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:51,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:48,  2.10s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:10<00:47,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:46,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:44,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:41,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:39,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:21<00:36,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:24<00:35,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:33,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:31,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:31<00:29,  2.28s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:33<00:27,  2.29s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:35<00:23,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:22,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:39<00:19,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:41<00:17,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:43<00:14,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:46<00:13,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:48<00:11,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:50<00:08,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:52<00:06,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:55<00:04,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:57<00:02,  2.23s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:58<00:00,  2.01s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.45batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.59batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.56batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.51batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.48batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.46batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.55batch/s]\n",
            "epoch: 29\t loss: 0.157057\t micro_f1: 0.5392\t macro_f1: 0.1421\n",
            "Training model:  15% 30/200 [37:58<3:26:51, 73.01s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:59,  2.28s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:55,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:53,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:51,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:11<00:49,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:47,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:45,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:18<00:42,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:20<00:40,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:22<00:38,  2.27s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:24<00:35,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:33,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:29<00:31,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:31<00:29,  2.28s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:33<00:25,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:35<00:23,  2.10s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:21,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:40<00:19,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:42<00:17,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:44<00:15,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:46<00:13,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:48<00:11,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:51<00:08,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:53<00:06,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:55<00:04,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:58<00:02,  2.26s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:59<00:00,  1.97s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.44batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.60batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.56batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.51batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.48batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.46batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.56batch/s]\n",
            "epoch: 30\t loss: 0.148644\t micro_f1: 0.5506\t macro_f1: 0.1309\n",
            "Training model:  16% 31/200 [39:07<3:22:22, 71.85s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:59,  2.30s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:56,  2.27s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:53,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:47,  2.08s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:10<00:46,  2.13s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:12<00:44,  2.10s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:42,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:41,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:39,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:21<00:37,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:23<00:34,  2.13s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:32,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:30,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:30<00:28,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:32<00:26,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:35<00:24,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:22,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:39<00:20,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:41<00:17,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:43<00:15,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:46<00:13,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:48<00:11,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:50<00:08,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:52<00:06,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:55<00:04,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:57<00:02,  2.25s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:58<00:00,  2.03s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.42batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.58batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.54batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:02,  1.49batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.47batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.46batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.55batch/s]\n",
            "epoch: 31\t loss: 0.141179\t micro_f1: 0.5549\t macro_f1: 0.1421\n",
            "Training model:  16% 32/200 [40:25<3:26:21, 73.70s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:59,  2.29s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:56,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:53,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:09<00:51,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:11<00:49,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:47,  2.27s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:45,  2.27s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:18<00:43,  2.27s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:20<00:40,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:22<00:38,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:24<00:36,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:27<00:34,  2.27s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:29<00:31,  2.28s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:31<00:28,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:33<00:26,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:36<00:24,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:38<00:22,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:40<00:20,  2.27s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:42<00:17,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:44<00:14,  2.11s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:46<00:12,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:48<00:10,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:50<00:08,  2.04s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:52<00:06,  2.08s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:54<00:04,  2.08s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:57<00:02,  2.13s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:58<00:00,  1.95s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.45batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.60batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.57batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.52batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.49batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.47batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.56batch/s]\n",
            "epoch: 32\t loss: 0.134479\t micro_f1: 0.5547\t macro_f1: 0.1455\n",
            "Training model:  16% 33/200 [41:38<3:24:00, 73.30s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:55,  2.13s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:54,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:52,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:50,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:11<00:49,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:46,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:44,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:39,  2.09s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:38,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:21<00:36,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:23<00:34,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:32,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:30,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:30<00:28,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:32<00:25,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:34<00:22,  2.05s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:36<00:21,  2.12s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:38<00:18,  2.10s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:40<00:17,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:43<00:15,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:45<00:13,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:47<00:11,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:50<00:08,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:51<00:06,  2.13s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:54<00:04,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:56<00:02,  2.20s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:58<00:00,  2.00s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.44batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.59batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.56batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.51batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.48batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.46batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.55batch/s]\n",
            "epoch: 33\t loss: 0.128888\t micro_f1: 0.5535\t macro_f1: 0.1557\n",
            "Training model:  17% 34/200 [42:49<3:21:13, 72.73s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:59,  2.30s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:56,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:54,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:09<00:51,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:11<00:49,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:47,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:45,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:18<00:42,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:20<00:40,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:22<00:38,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:24<00:36,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:27<00:33,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:29<00:31,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:31<00:29,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:33<00:27,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:36<00:24,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:38<00:21,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:40<00:19,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:42<00:17,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:44<00:15,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:47<00:13,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:49<00:10,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:51<00:08,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:53<00:06,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:55<00:04,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:58<00:02,  2.24s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:59<00:00,  2.03s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.44batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.60batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.57batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.51batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.48batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.46batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.55batch/s]\n",
            "epoch: 34\t loss: 0.122874\t micro_f1: 0.5544\t macro_f1: 0.1394\n",
            "Training model:  18% 35/200 [43:53<3:13:04, 70.21s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:56,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:54,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:53,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:48,  2.11s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:10<00:46,  2.11s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:12<00:45,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:43,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:41,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:39,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:21<00:37,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:24<00:35,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:33,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:31,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:30<00:28,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:32<00:26,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:35<00:24,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:22,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:39<00:20,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:41<00:17,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:43<00:14,  2.11s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:45<00:12,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:48<00:10,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:50<00:08,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:52<00:06,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:54<00:04,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:57<00:02,  2.23s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:58<00:00,  2.02s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.44batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.60batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.57batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.51batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.49batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:03<00:00,  1.48batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.57batch/s]\n",
            "epoch: 35\t loss: 0.118383\t micro_f1: 0.5517\t macro_f1: 0.1396\n",
            "Training model:  18% 36/200 [44:57<3:06:10, 68.11s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:55,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:55,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:51,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:50,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:10<00:47,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:46,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:44,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:39,  2.10s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:37,  2.08s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:21<00:35,  2.06s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:23<00:33,  2.12s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:25<00:32,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:30,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:30<00:28,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:32<00:26,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:34<00:24,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:22,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:39<00:20,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:41<00:17,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:43<00:15,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:46<00:13,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:48<00:11,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:50<00:08,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:52<00:06,  2.08s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:54<00:04,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:56<00:01,  1.99s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:57<00:00,  1.85s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.46batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.62batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.58batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.51batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.49batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.47batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.57batch/s]\n",
            "epoch: 36\t loss: 0.116361\t micro_f1: 0.5492\t macro_f1: 0.1387\n",
            "Training model:  18% 37/200 [45:59<3:00:08, 66.31s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:58,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:56,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:54,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:09<00:51,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:11<00:49,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:47,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:45,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:18<00:42,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:20<00:40,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:22<00:38,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:24<00:34,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:32,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:29<00:30,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:31<00:28,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:33<00:26,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:35<00:24,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:38<00:22,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:39<00:19,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:42<00:17,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:43<00:14,  2.00s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:46<00:12,  2.08s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:47<00:10,  2.00s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:49<00:08,  2.03s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:52<00:06,  2.04s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:54<00:04,  2.10s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:56<00:02,  2.15s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:57<00:00,  1.86s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.42batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.59batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.54batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:02,  1.48batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.47batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.46batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.55batch/s]\n",
            "epoch: 37\t loss: 0.112546\t micro_f1: 0.5533\t macro_f1: 0.1482\n",
            "Training model:  19% 38/200 [47:01<2:55:47, 65.11s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:58,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:56,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:52,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:50,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:11<00:49,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:47,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:44,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:41,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:39,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:22<00:37,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:24<00:33,  2.12s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:32,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:30,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:30<00:28,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:33<00:26,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:35<00:24,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:22,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:39<00:19,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:41<00:16,  2.11s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:43<00:14,  2.06s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:45<00:12,  2.07s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:47<00:10,  2.13s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:50<00:08,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:52<00:06,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:54<00:04,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:56<00:02,  2.23s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:57<00:00,  1.85s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.46batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.62batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.57batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.51batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.49batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.47batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.56batch/s]\n",
            "epoch: 38\t loss: 0.108751\t micro_f1: 0.5592\t macro_f1: 0.1446\n",
            "Training model:  20% 39/200 [48:11<2:58:20, 66.46s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:59,  2.28s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:56,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:53,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:49,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:11<00:48,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:12<00:43,  2.08s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:42,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:41,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:39,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:21<00:37,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:23<00:34,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:32,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:31,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:30<00:29,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:32<00:26,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:35<00:24,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:22,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:39<00:20,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:41<00:17,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:43<00:15,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:46<00:13,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:48<00:11,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:50<00:08,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:52<00:06,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:54<00:04,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:57<00:02,  2.24s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:58<00:00,  2.03s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.45batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.61batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.57batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.51batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.49batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.47batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.56batch/s]\n",
            "epoch: 39\t loss: 0.106250\t micro_f1: 0.5510\t macro_f1: 0.1528\n",
            "Training model:  20% 40/200 [49:14<2:54:40, 65.51s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:53,  2.07s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:54,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:51,  2.13s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:49,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:10<00:48,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:46,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:44,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:41,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:39,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:21<00:37,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:24<00:35,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:25<00:31,  2.08s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:29,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:30<00:27,  2.09s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:32<00:25,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:34<00:23,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:36<00:22,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:39<00:19,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:41<00:17,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:43<00:15,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:45<00:13,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:48<00:11,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:50<00:08,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:52<00:06,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:54<00:04,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:57<00:02,  2.25s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:58<00:00,  2.03s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.45batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.60batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.57batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.51batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.47batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.46batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.55batch/s]\n",
            "epoch: 40\t loss: 0.103403\t micro_f1: 0.5616\t macro_f1: 0.1572\n",
            "Training model:  20% 41/200 [50:31<3:03:07, 69.10s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:58,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:52,  2.10s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:50,  2.09s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:49,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:10<00:48,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:46,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:44,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:41,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:39,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:21<00:38,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:24<00:36,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:34,  2.28s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:31,  2.28s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:31<00:29,  2.29s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:33<00:27,  2.29s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:35<00:25,  2.29s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:22,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:39<00:19,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:42<00:17,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:44<00:15,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:46<00:13,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:49<00:11,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:51<00:09,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:53<00:06,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:55<00:04,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:58<00:02,  2.26s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:59<00:00,  1.99s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.45batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.61batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.57batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.52batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.49batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.47batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.57batch/s]\n",
            "epoch: 41\t loss: 0.102258\t micro_f1: 0.5569\t macro_f1: 0.1492\n",
            "Training model:  21% 42/200 [51:35<2:57:56, 67.57s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:58,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:56,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:53,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:51,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:11<00:49,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:44,  2.10s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:14<00:39,  1.98s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:16<00:39,  2.06s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:18<00:36,  2.02s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:21<00:35,  2.10s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:23<00:34,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:25<00:32,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:27<00:30,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:30<00:28,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:32<00:26,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:34<00:24,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:36<00:21,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:38<00:19,  2.11s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:40<00:17,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:43<00:15,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:44<00:12,  2.06s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:47<00:10,  2.12s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:49<00:08,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:51<00:06,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:53<00:04,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:56<00:02,  2.20s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:57<00:00,  2.00s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.45batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.60batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.57batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.51batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.48batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.47batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.56batch/s]\n",
            "epoch: 42\t loss: 0.099476\t micro_f1: 0.5709\t macro_f1: 0.1685\n",
            "Training model:  22% 43/200 [52:56<3:07:21, 71.60s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:53,  2.05s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:53,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:52,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:51,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:11<00:49,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:47,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:43,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:42,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:40,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:22<00:38,  2.27s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:24<00:34,  2.13s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:32,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:31,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:31<00:29,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:33<00:27,  2.27s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:35<00:24,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:22,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:40<00:20,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:42<00:17,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:44<00:15,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:46<00:13,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:48<00:11,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:51<00:08,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:53<00:06,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:55<00:04,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:57<00:02,  2.24s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:59<00:00,  2.03s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.44batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.60batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.57batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.51batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.49batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.47batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.57batch/s]\n",
            "epoch: 43\t loss: 0.097355\t micro_f1: 0.5600\t macro_f1: 0.1598\n",
            "Training model:  22% 44/200 [54:00<3:00:04, 69.26s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:54,  2.10s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:54,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:52,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:50,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:11<00:48,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:12<00:43,  2.06s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:14<00:41,  2.06s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:40,  2.12s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:38,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:21<00:37,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:23<00:33,  2.06s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:25<00:31,  2.12s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:27<00:30,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:30<00:28,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:32<00:26,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:34<00:24,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:36<00:22,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:39<00:20,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:41<00:17,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:43<00:15,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:45<00:13,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:47<00:11,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:50<00:08,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:52<00:06,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:54<00:04,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:56<00:02,  2.24s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:58<00:00,  2.03s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.42batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.57batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.53batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:02,  1.49batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.45batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.44batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.53batch/s]\n",
            "epoch: 44\t loss: 0.096056\t micro_f1: 0.5455\t macro_f1: 0.1459\n",
            "Training model:  22% 45/200 [55:03<2:54:06, 67.40s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:58,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:55,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:53,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:49,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:10<00:48,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:12<00:43,  2.05s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:42,  2.12s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:41,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:39,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:21<00:35,  2.08s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:23<00:34,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:25<00:31,  2.10s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:27<00:30,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:30<00:28,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:32<00:26,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:34<00:24,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:36<00:22,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:39<00:19,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:40<00:16,  2.11s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:43<00:15,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:45<00:13,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:47<00:10,  2.12s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:49<00:08,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:51<00:06,  2.13s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:54<00:04,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:56<00:02,  2.15s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:57<00:00,  1.97s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.45batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.61batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.57batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.52batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.49batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:03<00:00,  1.48batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.57batch/s]\n",
            "epoch: 45\t loss: 0.095556\t micro_f1: 0.5598\t macro_f1: 0.1593\n",
            "Training model:  23% 46/200 [56:05<2:48:57, 65.83s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:58,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:54,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:53,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:51,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:10<00:46,  2.12s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:45,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:43,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:16<00:37,  1.99s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:37,  2.07s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:21<00:36,  2.13s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:23<00:34,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:25<00:31,  2.07s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:27<00:29,  2.12s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:29<00:28,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:32<00:25,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:34<00:22,  2.09s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:36<00:21,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:38<00:19,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:40<00:17,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:43<00:15,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:45<00:13,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:47<00:11,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:49<00:08,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:52<00:06,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:54<00:04,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:56<00:02,  2.16s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:57<00:00,  1.88s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.45batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.59batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.57batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.51batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.48batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.46batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.55batch/s]\n",
            "epoch: 46\t loss: 0.093534\t micro_f1: 0.5697\t macro_f1: 0.1594\n",
            "Training model:  24% 47/200 [57:07<2:44:59, 64.70s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:58,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:56,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:54,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:45,  1.99s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:10<00:45,  2.08s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:12<00:44,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:14<00:41,  2.10s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:40,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:39,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:21<00:35,  2.11s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:23<00:34,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:25<00:32,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:30,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:30<00:27,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:32<00:25,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:34<00:24,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:36<00:21,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:38<00:19,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:41<00:17,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:43<00:15,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:45<00:13,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:47<00:11,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:49<00:08,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:52<00:06,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:54<00:04,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:56<00:02,  2.23s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:58<00:00,  2.02s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.42batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.56batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.55batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.50batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.48batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.47batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.56batch/s]\n",
            "epoch: 47\t loss: 0.092979\t micro_f1: 0.5528\t macro_f1: 0.1467\n",
            "Training model:  24% 48/200 [58:10<2:42:25, 64.11s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:57,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:53,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:49,  2.06s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:48,  2.11s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:10<00:47,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:12<00:45,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:44,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:42,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:40,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:21<00:38,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:24<00:35,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:33,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:31,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:30<00:29,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:33<00:27,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:35<00:24,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:22,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:39<00:20,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:41<00:17,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:44<00:15,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:46<00:13,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:48<00:11,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:50<00:08,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:53<00:06,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:55<00:04,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:57<00:02,  2.19s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:58<00:00,  1.99s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.45batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.60batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.57batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.51batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.49batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.47batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.56batch/s]\n",
            "epoch: 48\t loss: 0.091324\t micro_f1: 0.5562\t macro_f1: 0.1491\n",
            "Training model:  24% 49/200 [59:14<2:40:53, 63.93s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:58,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:56,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:49,  2.07s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:48,  2.10s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:10<00:47,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:45,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:44,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:40,  2.13s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:39,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:21<00:37,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:23<00:35,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:32,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:27<00:29,  2.09s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:29<00:26,  2.01s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:32<00:25,  2.09s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:34<00:23,  2.13s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:36<00:21,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:38<00:19,  2.19s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:41<00:17,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:43<00:15,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:45<00:13,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:47<00:11,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:49<00:08,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:51<00:06,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:54<00:04,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:56<00:02,  2.12s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:57<00:00,  1.95s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.42batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.58batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.54batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:02,  1.48batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.47batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.46batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.54batch/s]\n",
            "epoch: 49\t loss: 0.089308\t micro_f1: 0.5703\t macro_f1: 0.1644\n",
            "Training model:  25% 50/200 [1:00:16<2:38:34, 63.43s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:58,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:52,  2.10s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:52,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:50,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:11<00:48,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:45,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:44,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:42,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:40,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:22<00:38,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:24<00:35,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:33,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:31,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:31<00:29,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:33<00:26,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:35<00:24,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:21,  2.16s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:39<00:19,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:42<00:17,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:44<00:15,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:46<00:13,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:48<00:11,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:50<00:08,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:52<00:06,  2.09s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:55<00:04,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:57<00:02,  2.12s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:58<00:00,  1.90s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.45batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.60batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.57batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.50batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.48batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.47batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.56batch/s]\n",
            "epoch: 50\t loss: 0.088112\t micro_f1: 0.5547\t macro_f1: 0.1555\n",
            "Training model:  26% 51/200 [1:01:19<2:37:12, 63.30s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:58,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:56,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:54,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:09<00:51,  2.26s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:11<00:49,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:47,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:42,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:41,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:39,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:22<00:37,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:24<00:35,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:33,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:29,  2.09s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:30<00:27,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:32<00:26,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:35<00:24,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:22,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:39<00:20,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:41<00:17,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:44<00:15,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:46<00:13,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:48<00:11,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:50<00:08,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:52<00:06,  2.11s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:54<00:04,  2.15s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:56<00:02,  2.04s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:58<00:00,  1.89s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.43batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.58batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.54batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:02,  1.48batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.45batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.45batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.54batch/s]\n",
            "epoch: 51\t loss: 0.087706\t micro_f1: 0.5669\t macro_f1: 0.1672\n",
            "Training model:  26% 52/200 [1:02:22<2:35:47, 63.16s/Epoch]\n",
            "Epoch in progress:   0% 0/27 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch in progress:   4% 1/27 [00:02<00:57,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:   7% 2/27 [00:04<00:55,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  11% 3/27 [00:06<00:53,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  15% 4/27 [00:08<00:51,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  19% 5/27 [00:10<00:45,  2.08s/batch]\u001b[A\n",
            "Epoch in progress:  22% 6/27 [00:13<00:44,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  26% 7/27 [00:15<00:43,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  30% 8/27 [00:17<00:40,  2.11s/batch]\u001b[A\n",
            "Epoch in progress:  33% 9/27 [00:19<00:38,  2.13s/batch]\u001b[A\n",
            "Epoch in progress:  37% 10/27 [00:21<00:36,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  41% 11/27 [00:23<00:34,  2.14s/batch]\u001b[A\n",
            "Epoch in progress:  44% 12/27 [00:26<00:32,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  48% 13/27 [00:28<00:30,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  52% 14/27 [00:30<00:28,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  56% 15/27 [00:32<00:26,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  59% 16/27 [00:35<00:24,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  63% 17/27 [00:37<00:22,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  67% 18/27 [00:39<00:20,  2.24s/batch]\u001b[A\n",
            "Epoch in progress:  70% 19/27 [00:41<00:18,  2.25s/batch]\u001b[A\n",
            "Epoch in progress:  74% 20/27 [00:43<00:15,  2.18s/batch]\u001b[A\n",
            "Epoch in progress:  78% 21/27 [00:46<00:13,  2.21s/batch]\u001b[A\n",
            "Epoch in progress:  81% 22/27 [00:48<00:11,  2.22s/batch]\u001b[A\n",
            "Epoch in progress:  85% 23/27 [00:50<00:08,  2.23s/batch]\u001b[A\n",
            "Epoch in progress:  89% 24/27 [00:52<00:06,  2.17s/batch]\u001b[A\n",
            "Epoch in progress:  93% 25/27 [00:54<00:04,  2.20s/batch]\u001b[A\n",
            "Epoch in progress:  96% 26/27 [00:57<00:02,  2.22s/batch]\u001b[A\n",
            "Epoch in progress: 100% 27/27 [00:58<00:00,  1.88s/batch]\u001b[A\n",
            "                                                         \u001b[A\n",
            "Evaluation:   0% 0/7 [00:00<?, ?batch/s]\u001b[A\n",
            "Evaluation:  14% 1/7 [00:00<00:04,  1.44batch/s]\u001b[A\n",
            "Evaluation:  29% 2/7 [00:01<00:03,  1.61batch/s]\u001b[A\n",
            "Evaluation:  43% 3/7 [00:01<00:02,  1.57batch/s]\u001b[A\n",
            "Evaluation:  57% 4/7 [00:02<00:01,  1.51batch/s]\u001b[A\n",
            "Evaluation:  71% 5/7 [00:03<00:01,  1.49batch/s]\u001b[A\n",
            "Evaluation:  86% 6/7 [00:04<00:00,  1.47batch/s]\u001b[A\n",
            "Evaluation: 100% 7/7 [00:04<00:00,  1.56batch/s]\n",
            "epoch: 52\t loss: 0.086310\t micro_f1: 0.5634\t macro_f1: 0.1677\n",
            "Training model:  26% 53/200 [1:03:24<2:34:26, 63.04s/Epoch]Early stop!\n",
            "Training model:  26% 53/200 [1:03:24<2:55:53, 71.79s/Epoch]\n",
            "Some weights of StructureContrast were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'node_mask', 'structure_encoder.convs.0.nn.0.bias', 'structure_encoder.convs.0.nn.0.weight', 'structure_encoder.convs.0.nn.1.bias', 'structure_encoder.convs.0.nn.1.num_batches_tracked', 'structure_encoder.convs.0.nn.1.running_mean', 'structure_encoder.convs.0.nn.1.running_var', 'structure_encoder.convs.0.nn.1.weight', 'structure_encoder.convs.0.nn.3.bias', 'structure_encoder.convs.0.nn.3.weight', 'structure_encoder.convs.0.nn.4.bias', 'structure_encoder.convs.0.nn.4.num_batches_tracked', 'structure_encoder.convs.0.nn.4.running_mean', 'structure_encoder.convs.0.nn.4.running_var', 'structure_encoder.convs.0.nn.4.weight', 'structure_encoder.convs.1.nn.0.bias', 'structure_encoder.convs.1.nn.0.weight', 'structure_encoder.convs.1.nn.1.bias', 'structure_encoder.convs.1.nn.1.num_batches_tracked', 'structure_encoder.convs.1.nn.1.running_mean', 'structure_encoder.convs.1.nn.1.running_var', 'structure_encoder.convs.1.nn.1.weight', 'structure_encoder.convs.1.nn.3.bias', 'structure_encoder.convs.1.nn.3.weight', 'structure_encoder.convs.1.nn.4.bias', 'structure_encoder.convs.1.nn.4.num_batches_tracked', 'structure_encoder.convs.1.nn.4.running_mean', 'structure_encoder.convs.1.nn.4.running_var', 'structure_encoder.convs.1.nn.4.weight', 'structure_encoder.convs.2.nn.0.bias', 'structure_encoder.convs.2.nn.0.weight', 'structure_encoder.convs.2.nn.2.bias', 'structure_encoder.convs.2.nn.2.weight', 'structure_encoder.dim_align.1.bias', 'structure_encoder.dim_align.1.weight', 'text_proj.0.bias', 'text_proj.0.weight', 'text_proj.2.bias', 'text_proj.2.weight', 'trans_dup.0.bias', 'trans_dup.0.weight', 'trans_dup.2.bias', 'trans_dup.2.weight', 'trans_proj.0.bias', 'trans_proj.0.weight', 'trans_proj.2.bias', 'trans_proj.2.weight', 'tree_proj.0.bias', 'tree_proj.0.weight', 'tree_proj.2.bias', 'tree_proj.2.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Running evaluation testset: 100% 9/9 [00:05<00:00,  1.65it/s]\n",
            "Test performance with best_valmicro ↓\n",
            "micro-f1: 0.5484\n",
            "macro-f1: 0.1254\n",
            "Some weights of StructureContrast were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'node_mask', 'structure_encoder.convs.0.nn.0.bias', 'structure_encoder.convs.0.nn.0.weight', 'structure_encoder.convs.0.nn.1.bias', 'structure_encoder.convs.0.nn.1.num_batches_tracked', 'structure_encoder.convs.0.nn.1.running_mean', 'structure_encoder.convs.0.nn.1.running_var', 'structure_encoder.convs.0.nn.1.weight', 'structure_encoder.convs.0.nn.3.bias', 'structure_encoder.convs.0.nn.3.weight', 'structure_encoder.convs.0.nn.4.bias', 'structure_encoder.convs.0.nn.4.num_batches_tracked', 'structure_encoder.convs.0.nn.4.running_mean', 'structure_encoder.convs.0.nn.4.running_var', 'structure_encoder.convs.0.nn.4.weight', 'structure_encoder.convs.1.nn.0.bias', 'structure_encoder.convs.1.nn.0.weight', 'structure_encoder.convs.1.nn.1.bias', 'structure_encoder.convs.1.nn.1.num_batches_tracked', 'structure_encoder.convs.1.nn.1.running_mean', 'structure_encoder.convs.1.nn.1.running_var', 'structure_encoder.convs.1.nn.1.weight', 'structure_encoder.convs.1.nn.3.bias', 'structure_encoder.convs.1.nn.3.weight', 'structure_encoder.convs.1.nn.4.bias', 'structure_encoder.convs.1.nn.4.num_batches_tracked', 'structure_encoder.convs.1.nn.4.running_mean', 'structure_encoder.convs.1.nn.4.running_var', 'structure_encoder.convs.1.nn.4.weight', 'structure_encoder.convs.2.nn.0.bias', 'structure_encoder.convs.2.nn.0.weight', 'structure_encoder.convs.2.nn.2.bias', 'structure_encoder.convs.2.nn.2.weight', 'structure_encoder.dim_align.1.bias', 'structure_encoder.dim_align.1.weight', 'text_proj.0.bias', 'text_proj.0.weight', 'text_proj.2.bias', 'text_proj.2.weight', 'trans_dup.0.bias', 'trans_dup.0.weight', 'trans_dup.2.bias', 'trans_dup.2.weight', 'trans_proj.0.bias', 'trans_proj.0.weight', 'trans_proj.2.bias', 'trans_proj.2.weight', 'tree_proj.0.bias', 'tree_proj.0.weight', 'tree_proj.2.bias', 'tree_proj.2.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Running evaluation testset: 100% 9/9 [00:05<00:00,  1.63it/s]\n",
            "Test performance with best_valmacro ↓\n",
            "micro-f1: 0.5484\n",
            "macro-f1: 0.1254\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!ls config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uV3s7kgemsIn",
        "outputId": "d8b0edb1-d0da-4223-e11d-f9a1f44d6f16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/KLTN/HILL-master\n",
            "gclr.json  hgclr.json  hill.json\n"
          ]
        }
      ]
    }
  ]
}